{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train loop and auxilary functions for NSD project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from dataset_pytorch import NSDDataset\n",
    "from net import Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters and network parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "current_epoch = 0\n",
    "batch_size = 10\n",
    "learning_rate = 5e-3\n",
    "num_classes = 11\n",
    "\n",
    "# Network parameters\n",
    "channels = [72, 128, 128, 2] # Channels to be used in each ResBlock\n",
    "reductions = ['mean', 'mean', None] # Reduction to be used in ResBlock ('max', 'mean', None)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = NSDDataset('saved_data.pickle') # WARNING - dataset takes a lot of RAM (around 6 GB), loading onto insufficient device could cause crashing\n",
    "model = Net(channels=channels, reductions=reductions, num_classes=num_classes).to(device)\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function for results validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Function to calculate accuracy on the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Iter: [16 / 60]| Loss: 0.025"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\brejt\\OneDrive\\Plocha\\NUDZ\\train.ipynb Cell 10\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/brejt/OneDrive/Plocha/NUDZ/train.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m i \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/brejt/OneDrive/Plocha/NUDZ/train.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mwhile\u001b[39;00m current_epoch \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m n_epochs:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/brejt/OneDrive/Plocha/NUDZ/train.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39m# Load data\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/brejt/OneDrive/Plocha/NUDZ/train.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     targets, inputs \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39;49mget_batch(batch_size\u001b[39m=\u001b[39;49mbatch_size)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/brejt/OneDrive/Plocha/NUDZ/train.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     i \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/brejt/OneDrive/Plocha/NUDZ/train.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     targets \u001b[39m=\u001b[39m targets\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[1;32mc:\\Users\\brejt\\OneDrive\\Plocha\\NUDZ\\dataset_pytorch.py:45\u001b[0m, in \u001b[0;36mNSDDataset.get_batch\u001b[1;34m(self, batch_size)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[39massert batch_size <= len(self)\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[39mif batch_size >= len(self.possible_ids):\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[39mfor id in ids: self.possible_ids.remove(id)\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     44\u001b[0m ids \u001b[39m=\u001b[39m [\u001b[39m0\u001b[39m, \u001b[39m50\u001b[39m, \u001b[39m100\u001b[39m, \u001b[39m150\u001b[39m, \u001b[39m200\u001b[39m, \u001b[39m250\u001b[39m, \u001b[39m300\u001b[39m, \u001b[39m350\u001b[39m, \u001b[39m400\u001b[39m, \u001b[39m450\u001b[39m]\n\u001b[1;32m---> 45\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m[ids]\n",
      "File \u001b[1;32mc:\\Users\\brejt\\OneDrive\\Plocha\\NUDZ\\dataset_pytorch.py:23\u001b[0m, in \u001b[0;36mNSDDataset.__getitem__\u001b[1;34m(self, id)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39mid\u001b[39m: \u001b[39mlist\u001b[39m[\u001b[39mint\u001b[39m]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mtuple\u001b[39m[Tensor, Tensor]:\n\u001b[1;32m---> 23\u001b[0m     output_data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mget_spectrograms_train(i) \u001b[39mfor\u001b[39;49;00m i \u001b[39min\u001b[39;49;00m \u001b[39mid\u001b[39;49m]\n\u001b[0;32m     24\u001b[0m     output_data \u001b[39m=\u001b[39m [out \u001b[39mfor\u001b[39;00m out \u001b[39min\u001b[39;00m output_data \u001b[39mif\u001b[39;00m out[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m72\u001b[39m]\n\u001b[0;32m     25\u001b[0m     labels_encoded \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros((\u001b[39mlen\u001b[39m(output_data), \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mdrugs)))\n",
      "File \u001b[1;32mc:\\Users\\brejt\\OneDrive\\Plocha\\NUDZ\\dataset_pytorch.py:23\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39mid\u001b[39m: \u001b[39mlist\u001b[39m[\u001b[39mint\u001b[39m]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mtuple\u001b[39m[Tensor, Tensor]:\n\u001b[1;32m---> 23\u001b[0m     output_data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mget_spectrograms_train(i) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mid\u001b[39m]\n\u001b[0;32m     24\u001b[0m     output_data \u001b[39m=\u001b[39m [out \u001b[39mfor\u001b[39;00m out \u001b[39min\u001b[39;00m output_data \u001b[39mif\u001b[39;00m out[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m72\u001b[39m]\n\u001b[0;32m     25\u001b[0m     labels_encoded \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros((\u001b[39mlen\u001b[39m(output_data), \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mdrugs)))\n",
      "File \u001b[1;32mc:\\Users\\brejt\\OneDrive\\Plocha\\NUDZ\\dataset.py:165\u001b[0m, in \u001b[0;36mDataset.get_spectrograms_train\u001b[1;34m(self, id, cutoff_frequency)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[39mfor\u001b[39;00m ch \u001b[39min\u001b[39;00m channels:\n\u001b[0;32m    164\u001b[0m     sig \u001b[39m=\u001b[39m it[ch]\n\u001b[1;32m--> 165\u001b[0m     f, t, S \u001b[39m=\u001b[39m spectrogram(sig, fs, nperseg\u001b[39m=\u001b[39;49m\u001b[39m512\u001b[39;49m, noverlap\u001b[39m=\u001b[39;49m\u001b[39m256\u001b[39;49m)\n\u001b[0;32m    166\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m loaded:\n\u001b[0;32m    167\u001b[0m         cuttof_id \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mwhere(f \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m cutoff_frequency)[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\brejt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\signal\\_spectral_py.py:763\u001b[0m, in \u001b[0;36mspectrogram\u001b[1;34m(x, fs, window, nperseg, noverlap, nfft, detrend, return_onesided, scaling, axis, mode)\u001b[0m\n\u001b[0;32m    760\u001b[0m     noverlap \u001b[39m=\u001b[39m nperseg \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m8\u001b[39m\n\u001b[0;32m    762\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mpsd\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m--> 763\u001b[0m     freqs, time, Sxx \u001b[39m=\u001b[39m _spectral_helper(x, x, fs, window, nperseg,\n\u001b[0;32m    764\u001b[0m                                         noverlap, nfft, detrend,\n\u001b[0;32m    765\u001b[0m                                         return_onesided, scaling, axis,\n\u001b[0;32m    766\u001b[0m                                         mode\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mpsd\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m    768\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    769\u001b[0m     freqs, time, Sxx \u001b[39m=\u001b[39m _spectral_helper(x, x, fs, window, nperseg,\n\u001b[0;32m    770\u001b[0m                                         noverlap, nfft, detrend,\n\u001b[0;32m    771\u001b[0m                                         return_onesided, scaling, axis,\n\u001b[0;32m    772\u001b[0m                                         mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mstft\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\brejt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\signal\\_spectral_py.py:1896\u001b[0m, in \u001b[0;36m_spectral_helper\u001b[1;34m(x, y, fs, window, nperseg, noverlap, nfft, detrend, return_onesided, scaling, axis, mode, boundary, padded)\u001b[0m\n\u001b[0;32m   1894\u001b[0m     result \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconjugate(result) \u001b[39m*\u001b[39m result_y\n\u001b[0;32m   1895\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mpsd\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m-> 1896\u001b[0m     result \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mconjugate(result) \u001b[39m*\u001b[39m result\n\u001b[0;32m   1898\u001b[0m result \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m scale\n\u001b[0;32m   1899\u001b[0m \u001b[39mif\u001b[39;00m sides \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39monesided\u001b[39m\u001b[39m'\u001b[39m \u001b[39mand\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mpsd\u001b[39m\u001b[39m'\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "while current_epoch <= n_epochs:\n",
    "    # Load data\n",
    "    targets, inputs = dataset.get_batch(batch_size=batch_size)\n",
    "    i += 1\n",
    "    targets = targets.to(device)\n",
    "    inputs = inputs.to(device)\n",
    "\n",
    "    # Reset gradient after each iteration\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    predictions = model(inputs)\n",
    "    \n",
    "\n",
    "    # Backward pass\n",
    "    loss = loss_function(predictions, targets)\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Print during epoch (sanity check)\n",
    "    with torch.no_grad():\n",
    "        print(f\"\\rEpoch: {current_epoch + 1} Iter: [{i} / {int(len(dataset) / batch_size) + 1}]| Loss: {round(loss.item(), 3)}\", end='')\n",
    "    \n",
    "    # Print after each epoch to get current results\n",
    "    if current_epoch != dataset.epoch:\n",
    "        current_epoch = dataset.epoch\n",
    "        torch.save(model.state_dict(), )\n",
    "        i = 0\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
